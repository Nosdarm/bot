import asyncio
import aiosqlite
import json
import logging
import os
import re # Moved import re to top
from typing import Optional, List, Tuple, Any, Union, Dict

from bot.database.base_adapter import BaseDbAdapter

logger = logging.getLogger(__name__)

# Default path for the SQLite database file
DEFAULT_SQLITE_DB_PATH = "kvelin_bot_sqlite.db"
DATABASE_URL_ENV_VAR = "SQLITE_DATABASE_PATH" # Using a similar pattern as Postgres for consistency

class SQLiteAdapter(BaseDbAdapter):
    """
    Asynchronous adapter for SQLite database.
    """

    def __init__(self, db_path: Optional[str] = None):
        self._db_path = db_path or os.getenv(DATABASE_URL_ENV_VAR, DEFAULT_SQLITE_DB_PATH)
        self._conn: Optional[aiosqlite.Connection] = None
        logger.info(f"SQLiteAdapter initialized for database path: {self._db_path}")

    async def connect(self) -> None:
        if self._conn: # If _conn exists, assume it's open or will be handled by operations.
            # The is_closed() method is not standard/reliable on aiosqlite.Connection.
            # We can try a ping or rely on subsequent operations to fail if closed.
            # For simplicity here, if _conn is not None, we'll log and return.
            # A more robust check might involve `await self._conn.execute("SELECT 1")`
            logger.info("SQLiteAdapter: Connection object exists. Assuming connected or will be handled by operations.")
            return
        try:
            self._conn = await aiosqlite.connect(self._db_path)
            # Use row factory to get results as dictionaries
            self._conn.row_factory = aiosqlite.Row
            logger.info(f"SQLiteAdapter: Connection established to {self._db_path}.")
        except Exception as e:
            logger.error(f"SQLiteAdapter: Error connecting to database {self._db_path}: {e}", exc_info=True)
            raise

    async def close(self) -> None:
        if self._conn:
            try:
                await self._conn.close()
                logger.info(f"SQLiteAdapter: Connection closed to {self._db_path}.")
            except Exception as e:
                logger.error(f"SQLiteAdapter: Error closing connection to {self._db_path}: {e}", exc_info=True)
            finally:
                self._conn = None
        else:
            logger.info("SQLiteAdapter: No active connection to close.")

    async def _get_connection(self) -> aiosqlite.Connection:
        # If _conn is None, it means it was never connected or explicitly closed and set to None.
        if not self._conn:
            # logger.debug("SQLiteAdapter: Connection is None or presumed closed, attempting to connect.")
            await self.connect()
        if not self._conn: # Should be established by self.connect()
            raise ConnectionError("SQLiteAdapter: Failed to establish a database connection.")
        return self._conn

    def _replace_placeholders(self, sql: str) -> str:
        """Replaces $N placeholders with ? for SQLite."""
        # import re # Moved to top
        return re.sub(r"\$\d+", "?", sql)

    async def execute(self, sql: str, params: Optional[Union[Tuple, List]] = None) -> str:
        conn = await self._get_connection()
        sqlite_sql = self._replace_placeholders(sql)
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(sqlite_sql, params or [])
                await conn.commit()
                # For SQLite, execute doesn't directly return a status like "INSERT 1"
                # We can emulate it based on cursor.rowcount if needed, but it's not standard for all statements
                # For INSERT, UPDATE, DELETE, cursor.rowcount gives affected rows.
                # For other statements, it's often -1 or 0.
                # Returning a generic success message or row count.
                if cursor.rowcount >= 0:
                    action = sql.strip().split(" ", 1)[0].upper()
                    return f"{action} {cursor.rowcount}"
                return "EXECUTE successful" # Generic for commands not returning rowcount
        except Exception as e:
            logger.error(f"SQLiteAdapter: Error executing SQL: {sql} | params: {params} | {e}", exc_info=True)
            await self._handle_execution_error(conn, e)
            raise

    async def execute_insert(self, sql: str, params: Optional[Union[Tuple, List]] = None) -> Optional[Any]:
        conn = await self._get_connection()
        sqlite_sql = self._replace_placeholders(sql)
        try:
            # For SQLite, INSERT commands do not typically have a RETURNING clause like Postgres.
            # The ID is usually generated by the application (e.g., UUID) and passed in as a parameter.
            # Or, for INTEGER PRIMARY KEY AUTOINCREMENT, cursor.lastrowid would be used AFTER execute.
            # This method, to align with BaseDbAdapter's expectation of sometimes returning an ID,
            # will execute the command and, if an ID is part of the params and is expected to be "returned",
            # it's the caller's responsibility to manage this.
            # For simple INSERTs where ID is passed, we assume the SQL is just an INSERT.
            # If the SQL is an UPSERT (INSERT ON CONFLICT), SQLite doesn't have a straightforward
            # way to return whether it inserted or updated without more complex queries.

            # We will assume that if this method is called, the SQL is an INSERT or an UPSERT
            # where the primary key is part of the `params`.
            # We'll return the first parameter if it's an INSERT, assuming it's the ID.
            # This is a simplification and might need refinement based on actual usage in DBService.

            # Let's find the ID from params if it's an INSERT statement for a table that typically has client-generated ID.
            # This is heuristic. A better way would be for the calling code (DBService) to handle ID generation
            # and not expect `execute_insert` to magically return it for SQLite when IDs are not auto-incremented integers.

            await conn.execute(sql, params or [])
            await conn.commit()

            # Heuristic: if the SQL is an INSERT and params are provided, return the first param as the ID.
            # This matches how `create_entity` in DBService seems to operate, where the ID is generated
            # by the caller and included in the params.
            # This will NOT work for tables with auto-incrementing integer PKs where `lastrowid` is needed.
            # However, the tables defined in initialize_database use TEXT PKs.

            # A more robust approach for `create_entity` like patterns:
            # The ID is already known by the caller. `execute_insert` could just return this known ID.
            # For this to work, we need to know which param is the ID.
            # Example: If `id_field` was passed here, we could extract it.
            # For now, let's assume if params exist, the first one *might* be the ID.
            # This is still not great.

            # The most common use of `execute_insert` in `DBService` is via `create_entity`,
            # where `id_field` is known.
            # `PostgresAdapter` relies on `RETURNING id_field`.
            # `SQLiteAdapter` cannot do `RETURNING id_field` for non-integer PKs easily.
            #
            # The most straightforward fix is that `DBService.create_entity` should not expect
            # `execute_insert` to return the ID if the adapter is SQLite and PK is not int.
            # Or, `SQLiteAdapter.execute_insert` could be made smarter if it knew the id_field name.

            # Given current structure, let's just return None for SQLite for now,
            # and acknowledge that `DBService.create_entity` will need adjustment for SQLite
            # if it relies on the returned value from `execute_insert` for non-integer PKs.
            # ALTERNATIVELY: Assume the ID is the first parameter for INSERTs.
            if params and sqlite_sql.strip().upper().startswith("INSERT"): # Check based on sqlite_sql
                 # This is a big assumption: that the first param is the ID.
                 # It holds for `create_entity` if `id` is the first column in `data`.
                 # Let's make it None and force DBService to handle it.
                 pass # Returning None by default now

            return None # Modified: Returning None as a general case for SQLite for non-autoincrement PKs

        except Exception as e:
            logger.error(f"SQLiteAdapter: Error executing INSERT-like SQL: {sqlite_sql} | params: {params} | {e}", exc_info=True)
            await self._handle_execution_error(conn, e)
            raise

    async def execute_many(self, sql: str, data: List[Union[Tuple, List]]) -> None:
        conn = await self._get_connection()
        sqlite_sql = self._replace_placeholders(sql)
        try:
            await conn.executemany(sqlite_sql, data)
            await conn.commit()
        except Exception as e:
            logger.error(f"SQLiteAdapter: Error executing many SQL: {sqlite_sql} | data count: {len(data)} | {e}", exc_info=True)
            await self._handle_execution_error(conn, e)
            raise

    async def fetchall(self, sql: str, params: Optional[Union[Tuple, List]] = None) -> List[Dict[str, Any]]:
        conn = await self._get_connection()
        sqlite_sql = self._replace_placeholders(sql)
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(sqlite_sql, params or [])
                rows = await cursor.fetchall()
                return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"SQLiteAdapter: Error fetching all SQL: {sqlite_sql} | params: {params} | {e}", exc_info=True)
            raise

    async def fetchone(self, sql: str, params: Optional[Union[Tuple, List]] = None) -> Optional[Dict[str, Any]]:
        conn = await self._get_connection()
        sqlite_sql = self._replace_placeholders(sql)
        try:
            async with conn.cursor() as cursor:
                await cursor.execute(sqlite_sql, params or [])
                row = await cursor.fetchone()
                return dict(row) if row else None
        except Exception as e:
            logger.error(f"SQLiteAdapter: Error fetching one SQL: {sqlite_sql} | params: {params} | {e}", exc_info=True)
            raise

    async def _handle_execution_error(self, conn: aiosqlite.Connection, error: Exception):
        # Basic error handling, specific rollback logic might be needed if transactions are managed differently
        # For now, assume individual commits or explicit transaction blocks handle rollback.
        # This method is a placeholder for more sophisticated error handling if required.
        logger.debug(f"SQLiteAdapter: Handling execution error: {error}")
        # If a transaction system is implemented, this might call self.rollback()
        pass

    async def commit(self) -> None:
        conn = await self._get_connection()
        try:
            await conn.commit()
            logger.info("SQLiteAdapter: Transaction committed.")
        except Exception as e:
            logger.error(f"SQLiteAdapter: Error committing transaction: {e}", exc_info=True)
            # Attempt to rollback on commit error if supported/meaningful
            try:
                await conn.rollback()
                logger.info("SQLiteAdapter: Transaction rolled back due to commit error.")
            except Exception as rb_e:
                logger.error(f"SQLiteAdapter: Error during rollback after commit error: {rb_e}", exc_info=True)
            raise

    async def rollback(self) -> None:
        conn = await self._get_connection()
        try:
            await conn.rollback()
            logger.info("SQLiteAdapter: Transaction rolled back.")
        except Exception as e:
            logger.error(f"SQLiteAdapter: Error rolling back transaction: {e}", exc_info=True)
            raise

    async def initialize_database(self) -> None:
        """
        Initializes the database. For SQLite, this might involve creating tables
        if they don't exist. Schema management like Alembic is not used here.
        This is a placeholder and would need actual DDL statements.
        """
        conn = await self._get_connection()
        logger.info("SQLiteAdapter: Initializing database (checking schema if needed)...")
        # Example: Create a simple table if it doesn't exist
        # This is where you would put your DDL statements, ideally read from a schema file
        # or defined elsewhere.
        # await conn.execute("""
        # CREATE TABLE IF NOT EXISTS example_table (
        #    id INTEGER PRIMARY KEY AUTOINCREMENT,
        #    data TEXT
        # );
        # """)
        # await conn.commit()
        # For now, this method will be a no-op beyond ensuring connection.
        # Actual schema setup for SQLite will need to be handled by running DDL scripts separately
        # or by embedding them here.

        # Create tables if they don't exist
        # Note: SQLite types are flexible. Using TEXT for JSON, INTEGER for Boolean.
        # Timestamps are stored as TEXT in ISO8601 format.

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS pending_conflicts (
            id TEXT PRIMARY KEY,
            guild_id TEXT NOT NULL,
            conflict_data TEXT NOT NULL, -- JSON stored as TEXT
            status TEXT NOT NULL DEFAULT 'pending_gm_resolution',
            resolution_data TEXT, -- JSON stored as TEXT
            created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
            resolved_at TEXT
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_pending_conflicts_guild_id ON pending_conflicts (guild_id);")
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_pending_conflicts_status ON pending_conflicts (status);")

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS locations (
            id TEXT PRIMARY KEY,
            guild_id TEXT NOT NULL,
            template_id TEXT,
            name_i18n TEXT NOT NULL, -- JSON stored as TEXT
            descriptions_i18n TEXT NOT NULL, -- JSON stored as TEXT
            details_i18n TEXT, -- JSON stored as TEXT
            tags_i18n TEXT, -- JSON stored as TEXT
            atmosphere_i18n TEXT, -- JSON stored as TEXT
            features_i18n TEXT, -- JSON stored as TEXT
            exits TEXT, -- JSON stored as TEXT
            state_variables TEXT, -- JSON stored as TEXT
            is_active INTEGER NOT NULL DEFAULT 1, -- Boolean as INTEGER
            channel_id TEXT,
            image_url TEXT,
            static_name TEXT,
            static_connections TEXT, -- JSON stored as TEXT
            inventory TEXT, -- JSON stored as TEXT
            type_i18n TEXT NOT NULL -- JSON stored as TEXT (added based on model)
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_locations_guild_id ON locations (guild_id);")

        # Schema based on SQLiteAdapter's add_generated_location method parameters
        await conn.execute("""
        CREATE TABLE IF NOT EXISTS generated_locations (
            location_id TEXT PRIMARY KEY,
            guild_id TEXT NOT NULL,
            user_id TEXT NOT NULL,
            generated_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP
        );
        """)
        # No specific index needed for generated_locations based on current usage, PK lookup is fine.

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS pending_moderation_requests (
            id TEXT PRIMARY KEY,
            guild_id TEXT NOT NULL,
            user_id TEXT NOT NULL,
            content_type TEXT NOT NULL,
            data TEXT, -- JSON stored as TEXT
            status TEXT DEFAULT 'pending',
            created_at TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
            moderator_id TEXT,
            moderated_at TEXT,
            moderator_notes TEXT
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_pending_mod_req_guild_status ON pending_moderation_requests (guild_id, status);")

        # Adding more tables based on DBService usage:
        await conn.execute("""
        CREATE TABLE IF NOT EXISTS global_state (
            key TEXT PRIMARY KEY,
            value TEXT
        );
        """)

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS players (
            id TEXT PRIMARY KEY,
            discord_id TEXT,
            name_i18n TEXT, -- JSON
            current_location_id TEXT, -- FK to locations
            selected_language TEXT,
            xp INTEGER DEFAULT 0,
            level INTEGER DEFAULT 1,
            unspent_xp INTEGER DEFAULT 0,
            gold INTEGER DEFAULT 0,
            current_game_status TEXT,
            collected_actions_json TEXT, -- JSON
            current_party_id TEXT, -- FK to parties
            party_id TEXT, -- FK to parties
            guild_id TEXT NOT NULL,
            stats TEXT, -- JSON
            current_action TEXT,
            action_queue TEXT, -- JSON
            state_variables TEXT, -- JSON
            hp REAL,
            max_health REAL,
            is_alive INTEGER DEFAULT 1, -- Boolean
            status_effects TEXT, -- JSON
            race TEXT,
            mp INTEGER,
            attack INTEGER,
            defense INTEGER,
            skills_data_json TEXT, -- JSON
            abilities_data_json TEXT, -- JSON
            spells_data_json TEXT, -- JSON
            character_class TEXT,
            flags_json TEXT, -- JSON
            active_quests TEXT, -- JSON
            known_spells TEXT, -- JSON
            spell_cooldowns TEXT, -- JSON
            inventory TEXT, -- JSON
            effective_stats_json TEXT, -- JSON
            is_active INTEGER DEFAULT 1 NOT NULL,
            UNIQUE (discord_id, guild_id)
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_players_guild_id ON players (guild_id);")
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_players_is_active ON players (is_active);")

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS item_templates (
            id TEXT PRIMARY KEY,
            name_i18n TEXT NOT NULL, -- JSON
            description_i18n TEXT, -- JSON
            type TEXT,
            properties TEXT, -- JSON
            guild_id TEXT NOT NULL
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_item_templates_guild_id ON item_templates (guild_id);")

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS items (
            id TEXT PRIMARY KEY,
            template_id TEXT, -- FK to item_templates (optional)
            guild_id TEXT NOT NULL,
            owner_id TEXT,
            owner_type TEXT,
            location_id TEXT, -- FK to locations
            quantity INTEGER DEFAULT 1,
            state_variables TEXT, -- JSON
            is_temporary INTEGER DEFAULT 0, -- Boolean
            name_i18n TEXT, -- JSON (denormalized from template or custom)
            description_i18n TEXT, -- JSON (denormalized)
            properties TEXT, -- JSON (specific instance properties)
            slot TEXT,
            value INTEGER
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_items_guild_id ON items (guild_id);")
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_items_location_id ON items (location_id);")
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_items_owner_id ON items (owner_id);")

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS npcs (
            id TEXT PRIMARY KEY,
            template_id TEXT,
            name_i18n TEXT, -- JSON
            description_i18n TEXT, -- JSON
            backstory_i18n TEXT, -- JSON
            persona_i18n TEXT, -- JSON
            guild_id TEXT NOT NULL,
            location_id TEXT, -- FK to locations
            stats TEXT, -- JSON
            inventory TEXT, -- JSON
            current_action TEXT,
            action_queue TEXT, -- JSON
            party_id TEXT, -- FK to parties
            state_variables TEXT, -- JSON
            health REAL,
            max_health REAL,
            is_alive INTEGER DEFAULT 1, -- Boolean
            status_effects TEXT, -- JSON
            is_temporary INTEGER DEFAULT 0, -- Boolean
            archetype TEXT,
            traits TEXT, -- JSON
            desires TEXT, -- JSON
            motives TEXT, -- JSON
            skills_data TEXT, -- JSON
            equipment_data TEXT, -- JSON
            abilities_data TEXT, -- JSON
            faction TEXT, -- JSON
            behavior_tags TEXT, -- JSON
            loot_table_id TEXT,
            effective_stats_json TEXT -- JSON
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_npcs_guild_id ON npcs (guild_id);")
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_npcs_location_id ON npcs (location_id);")

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS guild_settings (
            guild_id TEXT NOT NULL,
            key TEXT NOT NULL,
            value TEXT, -- JSON stored as TEXT
            PRIMARY KEY (guild_id, key)
        );
        """)

        # Placeholder for other tables mentioned in DBService that might be needed:
        # inventory (association table player-item), game_logs, dialogues
        # These might be more complex due to relationships or specific data types.
        # For now, focusing on the main entity tables.

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS game_logs (
            id TEXT PRIMARY KEY,
            timestamp TEXT NOT NULL DEFAULT CURRENT_TIMESTAMP,
            guild_id TEXT NOT NULL,
            player_id TEXT,
            party_id TEXT,
            event_type TEXT NOT NULL,
            message_key TEXT,
            message_params TEXT, -- JSON
            location_id TEXT,
            involved_entities_ids TEXT, -- JSON
            description_i18n TEXT, -- JSON
            consequences_data TEXT, -- JSON
            details TEXT, -- JSON
            channel_id TEXT,
            is_undone INTEGER DEFAULT 0 -- Boolean, added based on DBService usage
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_game_logs_guild_id ON game_logs (guild_id);")
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_game_logs_player_id ON game_logs (player_id);")
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_game_logs_event_type ON game_logs (event_type);")

        await conn.execute("""
        CREATE TABLE IF NOT EXISTS dialogues (
            id TEXT PRIMARY KEY,
            guild_id TEXT NOT NULL,
            participants TEXT NOT NULL, -- JSON array of [player_id, npc_id]
            channel_id INTEGER,
            conversation_history TEXT, -- JSON array of messages
            state_variables TEXT, -- JSON object
            is_active INTEGER DEFAULT 1, -- Boolean
            last_activity_game_time REAL, -- Timestamp or float
            current_stage_id TEXT,
            template_id TEXT
        );
        """)
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_dialogues_guild_participants ON dialogues (guild_id, participants);")
        await conn.execute("CREATE INDEX IF NOT EXISTS idx_dialogues_active_last_activity ON dialogues (is_active, last_activity_game_time DESC);")


        await conn.commit()
        logger.info("SQLiteAdapter: Database schema initialized/verified.")

    async def begin_transaction(self) -> None:
        """
        Begins a new transaction.
        aiosqlite connections are in autocommit mode by default.
        To start a transaction, you can execute "BEGIN TRANSACTION"
        or rely on the implicit transaction started by DML statements
        that is then completed by commit() or rollback().
        For explicit control matching BaseDbAdapter:
        """
        conn = await self._get_connection()
        try:
            # await conn.execute("BEGIN TRANSACTION;") # Not always needed due to implicit transactions
            # aiosqlite's Connection object itself acts as a transaction context manager,
            # but for explicit begin/commit/rollback, we ensure the connection is ready.
            # Actual transaction start is often implicit with the first DML.
            # To be more explicit and similar to PostgresAdapter's begin():
            if not conn.in_transaction:
                 # This is a bit of a placeholder. `aiosqlite` doesn't have an explicit `begin()`
                 # like SQLAlchemy sessions. Transactions are typically managed by `await conn.commit()`
                 # or `await conn.rollback()`. For operations outside `async with conn:`,
                 # DML statements start a transaction implicitly.
                 # We can issue a BEGIN statement, but it's often not necessary.
                 # For now, this ensures the connection is active.
                 logger.info("SQLiteAdapter: Transaction context ensured (often implicit in aiosqlite).")
            else:
                 logger.info("SQLiteAdapter: Already in a transaction.")
        except Exception as e:
            logger.error(f"SQLiteAdapter: Error beginning transaction: {e}", exc_info=True)
            raise

    # --- Placeholder implementations for specialized methods ---
    # These will require careful translation of SQL and logic from PostgresAdapter

    async def save_pending_conflict(self, conflict_id: str, guild_id: str, conflict_data: str) -> None:
        # SQL must be SQLite compatible (e.g., JSON handling, ON CONFLICT)
        # SQLite has JSON1 extension, but syntax for upsert might differ.
        # Assuming conflict_data is a JSON string.
        sql = """
            INSERT INTO pending_conflicts (id, guild_id, conflict_data, created_at)
            VALUES (?, ?, ?, datetime('now'))
            ON CONFLICT(id) DO UPDATE SET
                guild_id = excluded.guild_id,
                conflict_data = excluded.conflict_data,
                created_at = datetime('now');
        """
        await self.execute(sql, (conflict_id, guild_id, conflict_data))
        logger.info(f"SQLiteAdapter: Saved pending conflict {conflict_id} for guild {guild_id}.")

    async def get_pending_conflict(self, conflict_id: str) -> Optional[Dict[str, Any]]:
        sql = "SELECT id, guild_id, conflict_data FROM pending_conflicts WHERE id = ?;"
        row = await self.fetchone(sql, (conflict_id,))
        if row and 'conflict_data' in row and isinstance(row['conflict_data'], str):
            try:
                row['conflict_data'] = json.loads(row['conflict_data'])
            except json.JSONDecodeError:
                logger.warning(f"SQLiteAdapter: Could not parse conflict_data JSON for {conflict_id}")
        return row

    async def delete_pending_conflict(self, conflict_id: str) -> None:
        sql = "DELETE FROM pending_conflicts WHERE id = ?;"
        await self.execute(sql, (conflict_id,))
        logger.info(f"SQLiteAdapter: Deleted pending conflict {conflict_id}.")

    async def get_pending_conflicts_by_guild(self, guild_id: str) -> List[Dict[str, Any]]:
        sql = "SELECT id, guild_id, conflict_data FROM pending_conflicts WHERE guild_id = ? ORDER BY created_at DESC;"
        rows = await self.fetchall(sql, (guild_id,))
        for row in rows:
            if row and 'conflict_data' in row and isinstance(row['conflict_data'], str):
                try:
                    row['conflict_data'] = json.loads(row['conflict_data'])
                except json.JSONDecodeError:
                     logger.warning(f"SQLiteAdapter: Could not parse conflict_data JSON during get_pending_conflicts_by_guild for guild {guild_id}")
        return rows

    async def save_pending_moderation_request(self, request_id: str, guild_id: str, user_id: str, content_type: str, data_json: str, status: str = 'pending') -> None:
        sql = """
            INSERT INTO pending_moderation_requests (id, guild_id, user_id, content_type, data, status, created_at)
            VALUES (?, ?, ?, ?, ?, ?, datetime('now'))
        """
        await self.execute(sql, (request_id, guild_id, user_id, content_type, data_json, status))
        logger.info(f"SQLiteAdapter: Saved pending moderation request {request_id}.")


    async def get_pending_moderation_request(self, request_id: str) -> Optional[Dict[str, Any]]:
        sql = "SELECT * FROM pending_moderation_requests WHERE id = ?;"
        row = await self.fetchone(sql, (request_id,))
        if row and 'data' in row and isinstance(row['data'], str):
            try:
                row['data'] = json.loads(row['data'])
            except json.JSONDecodeError:
                logger.warning(f"SQLiteAdapter: Could not parse data JSON for moderation request {request_id}")
        return row

    async def update_pending_moderation_request(
        self, request_id: str, status: str, moderator_id: Optional[str],
        data_json: Optional[str] = None, moderator_notes: Optional[str] = None
    ) -> bool:
        fields_to_update = ["status = ?", "moderator_id = ?", "moderated_at = datetime('now')"]
        params_list: List[Any] = [status, moderator_id]

        if data_json is not None:
            fields_to_update.append("data = ?")
            params_list.append(data_json)

        if moderator_notes is not None:
            fields_to_update.append("moderator_notes = ?")
            params_list.append(moderator_notes)

        params_list.append(request_id)

        sql = f"""
            UPDATE pending_moderation_requests
            SET {', '.join(fields_to_update)}
            WHERE id = ?;
        """
        # Execute returns a string like "UPDATE 1"
        result_status = await self.execute(sql, tuple(params_list))
        logger.info(f"SQLiteAdapter: Updated pending moderation request {request_id}. Status: {result_status}")
        return "UPDATE 1" in result_status or (isinstance(result_status, str) and result_status.startswith("UPDATE ") and int(result_status.split(" ")[1]) > 0)


    async def delete_pending_moderation_request(self, request_id: str) -> bool:
        sql = "DELETE FROM pending_moderation_requests WHERE id = ?;"
        result_status = await self.execute(sql, (request_id,))
        logger.info(f"SQLiteAdapter: Deleted pending moderation request {request_id}. Status: {result_status}")
        return "DELETE 1" in result_status or (isinstance(result_status, str) and result_status.startswith("DELETE ") and int(result_status.split(" ")[1]) > 0)

    async def get_pending_requests_by_guild(self, guild_id: str, status: str = 'pending') -> List[Dict[str, Any]]:
        sql = "SELECT * FROM pending_moderation_requests WHERE guild_id = ? AND status = ? ORDER BY created_at ASC;"
        rows = await self.fetchall(sql, (guild_id, status))
        for row in rows:
            if row and 'data' in row and isinstance(row['data'], str):
                try:
                    row['data'] = json.loads(row['data'])
                except json.JSONDecodeError:
                    logger.warning(f"SQLiteAdapter: Could not parse data JSON for moderation requests in guild {guild_id}")
        return rows

    async def add_generated_location(self, location_id: str, guild_id: str, user_id: str) -> None:
        sql = """
            INSERT INTO generated_locations (location_id, guild_id, user_id, generated_at)
            VALUES (?, ?, ?, datetime('now'))
            ON CONFLICT(location_id) DO NOTHING;
        """
        await self.execute(sql, (location_id, guild_id, user_id))
        logger.info(f"SQLiteAdapter: Added generated location {location_id} for user {user_id} in guild {guild_id}.")

    async def upsert_location(self, location_data: Dict[str, Any]) -> bool:
        if not location_data.get('id') or not location_data.get('guild_id'):
            logger.error("SQLiteAdapter: Error: Location data must include 'id' and 'guild_id' for upsert.")
            return False

        data_for_sql = {}
        for key, value in location_data.items():
            if isinstance(value, dict) or isinstance(value, list):
                data_for_sql[key] = json.dumps(value) # Store JSON as text
            else:
                data_for_sql[key] = value

        if 'is_active' not in data_for_sql or data_for_sql['is_active'] is None:
            data_for_sql['is_active'] = 1 # SQLite uses 0 and 1 for booleans

        columns = [
            'id', 'guild_id', 'template_id', 'name_i18n', 'descriptions_i18n',
            'details_i18n', 'tags_i18n', 'atmosphere_i18n', 'features_i18n',
            'exits', 'state_variables', 'is_active', 'channel_id', 'image_url',
            'static_name', 'static_connections', 'inventory'
        ]

        # Ensure all columns are present in data_for_sql, defaulting to None if missing
        values_list = [data_for_sql.get(col) for col in columns]

        # Construct SET clause for ON CONFLICT
        set_clauses = [f"{col} = excluded.{col}" for col in columns if col != 'id']

        sql = f"""
            INSERT INTO locations ({', '.join(columns)})
            VALUES ({', '.join(['?' for _ in columns])})
            ON CONFLICT (id) DO UPDATE SET
                {', '.join(set_clauses)};
        """
        try:
            status = await self.execute(sql, tuple(values_list))
            logger.info(f"SQLiteAdapter: Upserted location {location_data.get('id')}. Status: {status}")
            # Check if the operation was successful based on returned status
            return "INSERT 1" in status or "UPDATE 1" in status or \
                   (isinstance(status, str) and status.startswith(("INSERT ", "UPDATE ")) and int(status.split(" ")[1]) > 0)

        except Exception as e:
            logger.error(f"SQLiteAdapter: âŒ Error upserting location {location_data.get('id')}: {e}", exc_info=True)
            return False

    @property
    def supports_returning_id_on_insert(self) -> bool:
        return False

    @property
    def json_column_type_cast(self) -> Optional[str]:
        return None

logger.info("SQLiteAdapter module loaded.")

"""generate_alignment_migration

Revision ID: fcaa9d8b2630
Revises: acd0f397bcd8
Create Date: 2025-06-06 23:52:03.038683

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'fcaa9d8b2630'
down_revision: Union[str, None] = 'acd0f397bcd8'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

# Helper functions to make operations idempotent
def table_exists(table_name):
    conn = op.get_bind()
    return conn.dialect.has_table(conn, table_name)

def column_exists(table_name, column_name):
    conn = op.get_bind()
    try:
        if conn.dialect.name == 'postgresql':
            result = conn.execute(sa.text(
                f"SELECT 1 FROM information_schema.columns WHERE table_schema = 'public' AND table_name='{table_name}' AND column_name='{column_name}'"
            )).scalar_one_or_none()
            return result == 1
        else:
            insp = sa.inspect(conn)
            columns = insp.get_columns(table_name)
            return any(c['name'] == column_name for c in columns)
    except Exception:
        return False


def try_drop_column(table_name, column_name):
    if column_exists(table_name, column_name):
        # For columns that might be part of complex constraints or PKs in SQLite,
        # direct op.drop_column might fail. Consider batch mode if issues arise.
        # However, for simple column drops, this should generally be fine.
        op.drop_column(table_name, column_name)


def upgrade() -> None:
    """Upgrade schema."""
    # Attempt to clean up any orphaned temp table from previous failed batch operations
    op.execute('DROP TABLE IF EXISTS _alembic_tmp_inventory')
    op.execute('DROP TABLE IF EXISTS _alembic_tmp_locations')
    op.execute('DROP TABLE IF EXISTS _alembic_tmp_timers')

    # ### START Autogenerated by Alembic (for item_templates) ###
    if not table_exists('item_templates'):
        op.create_table('item_templates',
        sa.Column('id', sa.String(), nullable=False),
        sa.Column('name', sa.String(), nullable=False),
        sa.Column('description', sa.Text(), nullable=True),
        sa.Column('type', sa.String(), nullable=True),
        sa.Column('properties', sa.JSON(), nullable=True),
        sa.Column('guild_id', sa.String(), nullable=True),
        sa.PrimaryKeyConstraint('id')
        )
    # ### END Autogenerated by Alembic ###

    # ### START Manually added/verified commands to align with current models.py ###
    if not table_exists('logs'):
        op.create_table('logs',
        sa.Column('id', sa.String(), nullable=False),
        sa.Column('placeholder', sa.Text(), nullable=True),
        sa.PrimaryKeyConstraint('id')
        )

    if table_exists('guild_settings'): op.drop_table('guild_settings')
    if table_exists('game_logs'): op.drop_table('game_logs')
    if table_exists('pending_conflicts'): op.drop_table('pending_conflicts')
    if table_exists('dialogues'): op.drop_table('dialogues')
    if table_exists('pending_moderation_requests'): op.drop_table('pending_moderation_requests')

    if table_exists('generated_locations'):
        if not column_exists('generated_locations', 'placeholder'):
            op.add_column('generated_locations', sa.Column('placeholder', sa.Text(), nullable=True))
        try_drop_column('generated_locations', 'guild_id')
        try_drop_column('generated_locations', 'user_id')
        try_drop_column('generated_locations', 'generated_at')

    if table_exists('generated_npcs'):
        if not column_exists('generated_npcs', 'placeholder'):
             op.add_column('generated_npcs', sa.Column('placeholder', sa.Text(), nullable=True))
        try_drop_column('generated_npcs', 'skills_json')
        try_drop_column('generated_npcs', 'relationships_json')
        try_drop_column('generated_npcs', 'current_location_id')
        try_drop_column('generated_npcs', 'dialogue_hints_i18n')
        try_drop_column('generated_npcs', 'guild_id')
        try_drop_column('generated_npcs', 'motivation_i18n')
        try_drop_column('generated_npcs', 'role_i18n')
        try_drop_column('generated_npcs', 'is_hostile')
        try_drop_column('generated_npcs', 'ai_prompt_context_json')
        try_drop_column('generated_npcs', 'personality_i18n')
        try_drop_column('generated_npcs', 'abilities_json')
        try_drop_column('generated_npcs', 'faction_affiliations_json')
        try_drop_column('generated_npcs', 'backstory_i18n')
        try_drop_column('generated_npcs', 'name_i18n')
        try_drop_column('generated_npcs', 'inventory_json')
        try_drop_column('generated_npcs', 'spells_json')
        try_drop_column('generated_npcs', 'stats_json')

    if table_exists('inventory'):
        if not column_exists('inventory', 'id'):
             op.add_column('inventory', sa.Column('id', sa.String(), nullable=False, server_default=sa.text("gen_random_uuid()")))
        if column_exists('inventory', 'inventory_id'):
            with op.batch_alter_table('inventory', schema=None) as batch_op:
                batch_op.drop_column('inventory_id')
        try_drop_column('inventory', 'item_template_id')

    if table_exists('locations'):
        with op.batch_alter_table('locations', schema=None) as batch_op:
            if not column_exists('locations', 'is_active'):
                batch_op.add_column(sa.Column('is_active', sa.Boolean(), nullable=False, server_default=sa.true()))

            if not column_exists('locations', 'name_i18n'):
                batch_op.add_column(sa.Column('name_i18n', sa.JSON(), nullable=True))
            batch_op.alter_column('name_i18n',
                    existing_type=postgresql.JSONB(astext_type=sa.Text()),
                    type_=sa.JSON(),
                    existing_nullable=True)

            if not column_exists('locations', 'state_variables'):
                batch_op.add_column(sa.Column('state_variables', sa.JSON(), nullable=True))
            batch_op.alter_column('state_variables',
                    existing_type=postgresql.JSONB(astext_type=sa.Text()),
                    type_=sa.JSON(),
                    existing_nullable=True,
                    existing_server_default=False)

    if table_exists('players'):
        # Assuming simple column adds/drops are fine for players unless errors occur
        if not column_exists('players', 'discord_id'):
            op.add_column('players', sa.Column('discord_id', sa.Integer(), nullable=True))
        if not column_exists('players', 'inventory'):
            op.add_column('players', sa.Column('inventory', sa.JSON(), nullable=True))
        try_drop_column('players', 'discord_user_id')

    if table_exists('statuses'):
        # Assuming simple column adds/drops are fine for statuses unless errors occur
        if not column_exists('statuses', 'applied_at'):
            op.add_column('statuses', sa.Column('applied_at', sa.Integer(), nullable=True))
        try_drop_column('statuses', 'applied_at_time')

    if table_exists('timers'):
        with op.batch_alter_table('timers', schema=None) as batch_op:
            batch_op.alter_column('is_active',
                    existing_type=sa.BOOLEAN(),
                    server_default=None,
                    existing_nullable=False)
    # ### END Manually added commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # Attempt to clean up any orphaned temp table from previous failed batch operations
    op.execute('DROP TABLE IF EXISTS _alembic_tmp_inventory')
    op.execute('DROP TABLE IF EXISTS _alembic_tmp_locations')
    op.execute('DROP TABLE IF EXISTS _alembic_tmp_timers')

    # ### START Autogenerated by Alembic (for item_templates) ###
    if table_exists('item_templates'): op.drop_table('item_templates')
    # ### END Autogenerated by Alembic ###

    # ### START Manually added downgrade commands (best effort) ###
    if table_exists('timers'):
        with op.batch_alter_table('timers', schema=None) as batch_op:
            batch_op.alter_column('is_active',
                   existing_type=sa.BOOLEAN(),
                   server_default=sa.text('true'),
                   existing_nullable=False)

    if table_exists('statuses'):
        if column_exists('statuses', 'applied_at'):
             op.drop_column('statuses', 'applied_at') # Standard drop, assuming ok
        if not column_exists('statuses', 'applied_at_time'):
            op.add_column('statuses', sa.Column('applied_at_time', sa.INTEGER(), autoincrement=False, nullable=True))

    if table_exists('players'):
        if column_exists('players', 'discord_id'):
            op.drop_column('players', 'discord_id')
        if column_exists('players', 'inventory'):
            op.drop_column('players', 'inventory')
        if not column_exists('players', 'discord_user_id'):
            op.add_column('players', sa.Column('discord_user_id', sa.INTEGER(), autoincrement=False, nullable=True))

    if table_exists('locations'):
        with op.batch_alter_table('locations', schema=None) as batch_op:
            if column_exists('locations', 'is_active'):
                batch_op.drop_column('is_active')

            batch_op.alter_column('state_variables',
                   existing_type=sa.JSON(),
                   type_=postgresql.JSONB(astext_type=sa.Text()),
                   existing_nullable=True,
                   server_default=sa.text("'{}'::jsonb"))
            # If we had a flag: if column_exists('locations', 'state_variables_added_by_fcaa9d8b2630'):
            #    batch_op.drop_column('state_variables')

            batch_op.alter_column('name_i18n',
                   existing_type=sa.JSON(),
                   type_=postgresql.JSONB(astext_type=sa.Text()),
                   existing_nullable=True)
            # If we had a flag: if column_exists('locations', 'name_i18n_added_by_fcaa9d8b2630'):
            #    batch_op.drop_column('name_i18n')


    if table_exists('inventory'):
        # Batch mode might be needed if 'id' was PK or had complex constraints
        with op.batch_alter_table('inventory', schema=None) as batch_op:
            if column_exists('inventory', 'id'): batch_op.drop_column('id')
        # Add back old columns if needed for downgrade logic
        # if not column_exists('inventory', 'inventory_id'):
        #     op.add_column('inventory', sa.Column('inventory_id', sa.VARCHAR(), autoincrement=False, nullable=False, server_default='temp'))
        # if not column_exists('inventory', 'item_template_id'):
        #     op.add_column('inventory', sa.Column('item_template_id', sa.VARCHAR(), server_default=sa.text("'unknown_template'::character varying"), autoincrement=False, nullable=False))

    if table_exists('generated_npcs'):
        try_drop_column('generated_npcs', 'placeholder')

    if table_exists('generated_locations'):
        try_drop_column('generated_locations', 'placeholder')

    if table_exists('logs'):
        op.drop_.table('logs')

    # ### END Manually added downgrade commands ###
